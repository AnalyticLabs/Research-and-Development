{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arabic_Sentiment_Analysis_(AraVec) (2).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "khd2S__ge-Qh",
        "j2amLDvZfY-Z",
        "hZx-VtQqpwRs",
        "37I5JNiZqmq-",
        "P8ImVzHRrUAN",
        "U9jdWbVfrfal",
        "6Ko9YNgfsn2B"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQbhljtRY4L",
        "colab_type": "code",
        "outputId": "28a1ccfd-020c-4aef-9c7c-89a9c7cd109d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "!pip install --upgrade tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
            "\r\u001b[K     |█████▌                          | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed tqdm-4.43.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrhKLoiMoFXx",
        "colab_type": "code",
        "outputId": "1f5dd7a0-a81c-493d-eda3-4af6ca6ab530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwD-KY6voNg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/3-class.csv 3-class.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t34yXZ2ob38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/list.txt list.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nuz7UmEmouTS",
        "colab_type": "code",
        "outputId": "374ceabc-fa4d-4b3d-b1a4-4d92c62eaa3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('3-class.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet Polarity\n",
              "0   ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...      neg\n",
              "1   اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...      neg\n",
              "2   اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...      neg\n",
              "3   اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...      neg\n",
              "4   الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...      neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV6oCwqApCqU",
        "colab_type": "code",
        "outputId": "b84b8cd9-b32f-4e9a-fc7c-e5970155e6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56674 entries, 0 to 56673\n",
            "Data columns (total 2 columns):\n",
            "Tweet       56674 non-null object\n",
            "Polarity    56674 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 885.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-00vtx2_pLwD",
        "colab_type": "code",
        "outputId": "c0949dff-571b-4e18-b836-59b38f8487ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "df.Polarity.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neg     20731\n",
              "neut    18726\n",
              "pos     17217\n",
              "Name: Polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vESnb2pDboPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hu1CFuvpV-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Polarity'] = df['Polarity'].map({'neg': 0, 'pos': 1, 'neut': 2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRBTZLXup8Wv",
        "colab_type": "code",
        "outputId": "94c76e0a-8068-4950-f985-fb40af281d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "df[df.Polarity == 0].head(10)\n",
        "# df[df.Polarity == 1].head(10)\n",
        "# df[df.Polarity == 2].head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>الاعلام اللبناني يهاجم السعوديه منذ مده بكل ق...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>البرنامج استاجر بعض المشاهير و الهوامير في تو...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>الخرج بيض الله وجه محافظ الخرج فهذه القناه تص...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>الرياض السعوديه رسالتي لوزير العمل في حينه عن...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Polarity\n",
              "0   ابراهيم_عيسى الوسخ ابن الوسخه كلما حصل حادث ا...         0\n",
              "1   اخطر حروب الارض حرب العقيده حسيبك الله ي اول ...         0\n",
              "2   اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال ...         0\n",
              "3   اعلامنا متمثل في داوودالشريان و روتانا وطقتهم...         0\n",
              "4   الاصرار مرتزقه_برنامج_الاصرار بضاعه هالمترديه...         0\n",
              "5   الاعلام اللبناني يهاجم السعوديه منذ مده بكل ق...         0\n",
              "6   البرنامج استاجر بعض المشاهير و الهوامير في تو...         0\n",
              "7   الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا...         0\n",
              "8   الخرج بيض الله وجه محافظ الخرج فهذه القناه تص...         0\n",
              "9   الرياض السعوديه رسالتي لوزير العمل في حينه عن...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAPpasJWvpn1",
        "colab_type": "text"
      },
      "source": [
        "###Data Preparartion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aORnf61Bv4m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['pre_clean_len'] = [len(t) for t in df.Tweet]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsKnSDGjwDny",
        "colab_type": "code",
        "outputId": "45b1e13f-f8cd-4693-9b86-6832f6f73795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from pprint import pprint\n",
        "data_dict = {\n",
        "    'polarity': {\n",
        "        'type': df.Polarity.dtype,\n",
        "        'description': 'sentiment class - 0: negative, 1: positive, 2: neutral'\n",
        "    },\n",
        "    'tweet': {\n",
        "        'type': df.Tweet.dtype,\n",
        "        'description': 'tweet text'\n",
        "    },\n",
        "    'pre_clean_len': {\n",
        "        'type': df.pre_clean_len.dtype,\n",
        "        'description': 'length of the tweet before cleaning'\n",
        "    },\n",
        "    'dataset.shape': df.shape\n",
        "}\n",
        "\n",
        "pprint(data_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset.shape': (56674, 3),\n",
            " 'polarity': {'description': 'sentiment class - 0: negative, 1: positive, 2: '\n",
            "                             'neutral',\n",
            "              'type': dtype('int64')},\n",
            " 'pre_clean_len': {'description': 'length of the tweet before cleaning',\n",
            "                   'type': dtype('int64')},\n",
            " 'tweet': {'description': 'tweet text', 'type': dtype('O')}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKOxiSLp42v4",
        "colab_type": "text"
      },
      "source": [
        "* In some tweets the HTML encodings are not converted to \n",
        "text, so we'll convert the HTML decoding to general text. We can use beautiful soup for decoding the HTML encodings.\n",
        "\n",
        "* We also have to remove the '@' charcter mentions as it is not relevant to us.\n",
        "\n",
        "* We'll also remove the URL links as they contain little significance for our task.\n",
        "\n",
        "* We have to remove hashtag and numbers from the tweets too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6WheXAW5Yem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data cleaning function definition\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZLF1BhD73oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    #stopWords=[]\n",
        "    #stopwords_name='list.txt'\n",
        "    #with open(stopwords_name,encoding='utf-8') as f:\n",
        "        #line=f.readline()\n",
        "        #while line:\n",
        "            #stopWords.append(line[:-1])\n",
        "            #line=f.readline()           \n",
        "        #stopWords=set(stopWords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipySzOTD59xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "pat1 = r'@[A-Za-z0-9_]+'\n",
        "pat2 = r'https?://[^ ]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "www_pat = r'www.[^ ]+'\n",
        "arabic_num_pat = '[٠١٢٣٤٥٦٧٨٩]'\n",
        "eng_num_pat = '[0123456789]'\n",
        "sharta_pat = '[_]'\n",
        "eng_pat = '[A-Za-z]'\n",
        "\n",
        "def tweet_cleaner(text):\n",
        "  soup = BeautifulSoup(text, 'lxml')\n",
        "  souped = soup.get_text()\n",
        "  try:\n",
        "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "  except:\n",
        "        bom_removed = souped\n",
        "  stripped = re.sub(combined_pat, '', bom_removed)\n",
        "  stripped = re.sub(www_pat, '', stripped)\n",
        "  stripped = re.sub(arabic_num_pat, '', stripped)\n",
        "  stripped = re.sub(eng_num_pat, '', stripped)\n",
        "  stripped = re.sub(sharta_pat, ' ', stripped)\n",
        "  stripped = re.sub(eng_pat, ' ', stripped)\n",
        "  #stripped = re.sub(stopWords, ' ', stripped)\n",
        "  \n",
        "\n",
        "  words = [x for x in tok.tokenize(stripped) if len(x) > 1]\n",
        "  return (\" \".join(words)).strip()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlW8s5AVCC38",
        "colab_type": "code",
        "outputId": "5e53e960-a08f-401c-bfe4-3bdf34100d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "df_copy = df\n",
        "clean_tweet_texts = []\n",
        "for i in range(0, len(df)):\n",
        "  if( (i+1)%10000 == 0 ):\n",
        "        print(\"Tweets %d of %d has been processed\"%(i+1,len(df)))                                                                    \n",
        "  clean_tweet_texts.append(tweet_cleaner(df_copy['Tweet'][i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweets 10000 of 56674 has been processed\n",
            "Tweets 20000 of 56674 has been processed\n",
            "Tweets 30000 of 56674 has been processed\n",
            "Tweets 40000 of 56674 has been processed\n",
            "Tweets 50000 of 56674 has been processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGZHXprAHWmO",
        "colab_type": "code",
        "outputId": "c698389f-c9cf-418a-80d2-7454ff5d8e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "clean_tweet_texts[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ابراهيم عيسى الوسخ ابن الوسخه كلما حصل حادث اتهم السعوديه بالارهاب الكلب كان براتب مليون جنيه من سنوي مصر',\n",
              " 'اخطر حروب الارض حرب العقيده حسيبك الله اول ال راه يم رب عل نا وق ده الع يده وات زا',\n",
              " 'اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال خبثها اين مسؤولي الجمعيه من هذا نطالب خادم الحرمين بايقاف',\n",
              " 'اعلامنا متمثل في داوودالشريان روتانا وطقتهم كيف ترجي من هالاشكال خير همهم الوحيد في الحياه قياده المراه للسياره',\n",
              " 'الاصرار مرتزقه برنامج الاصرار بضاعه هالمترديه قناه العهر مزجاه في جميع المجالات',\n",
              " 'الاعلام اللبناني يهاجم السعوديه منذ مده بكل قبيح ومجموعه تدعم الاعلام في لبنان باقامه برامجها الضخمه فيها',\n",
              " 'البرنامج استاجر بعض المشاهير الهوامير في تويتر عشان يبررو لهم ويرقعو لقناه برنامج اصرار',\n",
              " 'الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا همه الشحاذه من على حساب مواطن يفضح برنامج الاصرار برعايه',\n",
              " 'الخرج بيض الله وجه محافظ الخرج فهذه القناه تصب على المسلمين سيل من المخالفات الشرعيه والمحرمات تدعو الى الرذيله وتشوه صوره الاسلام',\n",
              " 'الرياض السعوديه رسالتي لوزير العمل في حينه عن برنامج اصرار برنامج حتي بفكرته منسوخ بشكل مبتذل وفاشل']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDss3S9uFUEa",
        "colab_type": "code",
        "outputId": "6c7e145b-227a-4136-e5ee-f3210efad049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(clean_tweet_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu_LoP3cGlUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalization\n",
        "def normalizeArabic(text):\n",
        "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"و\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    return(text)\n",
        "for i in range(len(clean_tweet_texts)):\n",
        "  clean_tweet_texts[i] = normalizeArabic(clean_tweet_texts[i])\n",
        "#repeated letters\n",
        "import re\n",
        "for i in range(len(clean_tweet_texts)):\n",
        "  clean_tweet_texts[i] = re.sub(r'(.)\\1+', r'\\1\\1', clean_tweet_texts[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DquP-2Yc9I-3",
        "colab_type": "code",
        "outputId": "bd522e52-a0d6-4a7d-ec06-c97a086370ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "clean_tweet_texts[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ابراهيم عيسي الوسخ ابن الوسخه كلما حصل حادث اتهم السعوديه بالارهاب الكلب كان براتب مليون جنيه من سنوي مصر',\n",
              " 'اخطر حروب الارض حرب العقيده حسيبك الله اول ال راه يم رب عل نا وق ده الع يده وات زا',\n",
              " 'اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال خبثها اين مسوولي الجمعيه من هذا نطالب خادم الحرمين بايقاف',\n",
              " 'اعلامنا متمثل في داوودالشريان روتانا وطقتهم كيف ترجي من هالاشكال خير همهم الوحيد في الحياه قياده المراه للسياره',\n",
              " 'الاصرار مرتزقه برنامج الاصرار بضاعه هالمترديه قناه العهر مزجاه في جميع المجالات',\n",
              " 'الاعلام اللبناني يهاجم السعوديه منذ مده بكل قبيح ومجموعه تدعم الاعلام في لبنان باقامه برامجها الضخمه فيها',\n",
              " 'البرنامج استاجر بعض المشاهير الهوامير في تويتر عشان يبررو لهم ويرقعو لقناه برنامج اصرار',\n",
              " 'الحمد لله ما احتاج اتعلم من واحد فاشل اخلاقيا همه الشحاذه من علي حساب مواطن يفضح برنامج الاصرار برعايه',\n",
              " 'الخرج بيض الله وجه محافظ الخرج فهذه القناه تصب علي المسلمين سيل من المخالفات الشرعيه والمحرمات تدعو الي الرذيله وتشوه صوره الاسلام',\n",
              " 'الرياض السعوديه رسالتي لوزير العمل في حينه عن برنامج اصرار برنامج حتي بفكرته منسوخ بشكل مبتذل وفاشل']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xrjnuxlDPqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_df = pd.DataFrame(clean_tweet_texts, columns=['text'])\n",
        "clean_df['target'] = df.Polarity\n",
        "clean_df.to_csv('clean_tweet.csv', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H6e4zCP3Sitm",
        "outputId": "a6027768-062e-498d-8dd0-cdcd878261b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/clean_tweet.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: missing destination file operand after '/content/drive/My Drive/Colab Notebooks/clean_tweet.csv'\n",
            "Try 'cp --help' for more information.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n7f5Q3UAShkU",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlinBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VUwtEhbcqbG",
        "colab_type": "code",
        "outputId": "5abcc528-73a6-4f47-b832-30d033f44008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "csv = 'clean_tweet.csv'\n",
        "my_df = pd.read_csv(csv, index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ابراهيم عيسي الوسخ ابن الوسخه كلما حصل حادث ات...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>اخطر حروب الارض حرب العقيده حسيبك الله اول ال ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال خ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اعلامنا متمثل في داوودالشريان روتانا وطقتهم كي...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الاصرار مرتزقه برنامج الاصرار بضاعه هالمترديه ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  ابراهيم عيسي الوسخ ابن الوسخه كلما حصل حادث ات...       0\n",
              "1  اخطر حروب الارض حرب العقيده حسيبك الله اول ال ...       0\n",
              "2  اصبحت تقدم برامج عبر الجمعيات الخيريه لايصال خ...       0\n",
              "3  اعلامنا متمثل في داوودالشريان روتانا وطقتهم كي...       0\n",
              "4  الاصرار مرتزقه برنامج الاصرار بضاعه هالمترديه ...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_TsqTC8cxRN",
        "colab_type": "code",
        "outputId": "a830c68c-f8da-4970-d5a4-59517e21007c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "my_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 56674 entries, 0 to 56673\n",
            "Data columns (total 2 columns):\n",
            "text      56673 non-null object\n",
            "target    56674 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMwBZrMZc16e",
        "colab_type": "code",
        "outputId": "48779483-b672-4b3e-f46a-c426000ed6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "my_df.dropna(inplace=True)\n",
        "my_df.reset_index(drop=True, inplace=True)\n",
        "my_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56673 entries, 0 to 56672\n",
            "Data columns (total 2 columns):\n",
            "text      56673 non-null object\n",
            "target    56673 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 885.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFgamH4FwT",
        "colab_type": "text"
      },
      "source": [
        "#**Here put word vectorizer code that shows most occurence words**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtxgXVhQ4VgI",
        "colab_type": "text"
      },
      "source": [
        "#**after that reclean the cleaned dataset my_df using stopword**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O4IehAzdsrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = my_df.text\n",
        "y = my_df.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfOb-XOoc91b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "SEED = 666\n",
        "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.2, random_state=SEED)\n",
        "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiQ8oEm0dpfR",
        "colab_type": "code",
        "outputId": "3bcde31e-1c99-4976-e97f-793b7b526760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive, {3:.2f}% neutral\".format(len(x_train),\n",
        "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
        "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100,\n",
        "                                                                            (len(x_train[y_train == 2]) / (len(x_train)*1.))*100))\n",
        "print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive, {3:.2f}% neutral\".format(len(x_validation),\n",
        "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
        "                                                                            (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100,\n",
        "                                                                            (len(x_validation[y_validation == 2]) / (len(x_validation)*1.))*100))\n",
        "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive, {3:.2f}% neutral\".format(len(x_test),\n",
        "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
        "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100,\n",
        "                                                                            (len(x_test[y_test == 2]) / (len(x_test)*1.))*100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set has total 45338 entries with 36.59% negative, 30.52% positive, 32.90% neutral\n",
            "Validation set has total 5667 entries with 36.07% negative, 29.93% positive, 34.00% neutral\n",
            "Test set has total 5668 entries with 37.01% negative, 29.73% positive, 33.26% neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ec26c9c9-710b-4bd5-86b1-03b5972780ca",
        "id": "sr2yuopPkbz0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "#converting the labels to categorical data\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45338, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmujBZdFkcL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_validation = to_categorical(y_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW73-Bbjkhpi",
        "colab_type": "code",
        "outputId": "b8e66a51-19d6-4f43-df1a-580d183a4a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_validation.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5667, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRHL71yBr-46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa-qaCelztQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/full_uni_cbow_100_twitter.zip /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAR74UNqztIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Colab\\ Notebooks/full_uni_sg_100_twitter.zip /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4-VCr5rz_ur",
        "colab_type": "code",
        "outputId": "4d7c03c7-3ee1-4a0c-fc46-749d38b37875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!unzip full_uni_cbow_100_twitter.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  full_uni_cbow_100_twitter.zip\n",
            "  inflating: full_uni_cbow_100_twitter.mdl  \n",
            "  inflating: full_uni_cbow_100_twitter.mdl.trainables.syn1neg.npy  \n",
            "  inflating: full_uni_cbow_100_twitter.mdl.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqghaWIo08zk",
        "colab_type": "code",
        "outputId": "3d69a9c1-9d3f-4b95-a51d-033f3f185e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!unzip full_uni_sg_100_twitter.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  full_uni_sg_100_twitter.zip\n",
            "  inflating: full_uni_sg_100_twitter.mdl  \n",
            "  inflating: full_uni_sg_100_twitter.mdl.trainables.syn1neg.npy  \n",
            "  inflating: full_uni_sg_100_twitter.mdl.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Zp17qHRdVA",
        "colab_type": "code",
        "outputId": "c7650751-b8f6-453e-b7af-addcab16e744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model_ug_cbow = KeyedVectors.load('full_uni_cbow_100_twitter.mdl')\n",
        "model_ug_sg = KeyedVectors.load('full_uni_cbow_100_twitter.mdl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u__H4P17RyF0",
        "colab_type": "code",
        "outputId": "799ed8b6-7883-4622-df8d-fbdcbda06b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(model_ug_cbow.wv.vocab.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1259756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wEJVLTRR2A1",
        "colab_type": "code",
        "outputId": "a1dc6277-aa15-4df7-9ff7-58ea219cf672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "for w in model_ug_cbow.wv.vocab.keys():\n",
        "  embeddings_index[w] = np.append(model_ug_cbow.wv[w], \n",
        "                                  model_ug_sg.wv[w])\n",
        "print(f'Found {len(embeddings_index)} word vectors.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1259756 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swk3yKJjUAvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "sequences = tokenizer.texts_to_sequences(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacbNhkvVVmM",
        "colab_type": "code",
        "outputId": "2a455eff-6ce4-417f-9e66-263c857d8389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74239"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN0VBOzHVY0U",
        "colab_type": "code",
        "outputId": "a000118c-f57b-45a1-e371-2b45bd12b8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for x in x_train[:5]:\n",
        "  print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "لماذا يا خوله العنزي انا ماعلي منها هذي حياتها وبلعنتها بس ليش يطلعونها بالتلفزيون انها واجهه مشرفه وكل الشعب يدري انها عار السعوديه\n",
            "لماذا يا خوله العنزي فالرجاا كل واحد يبلع تبن وينطم والله بيحاسب كل واححد بطلو لقاافه\n",
            "الف مبروك زعماا البطوله للتوضيح بطولات الهلال في سنه واحده بجده والثانيه بلندن والثالثه الرياض مدلع جمهوره بكل مكان الهل\n",
            "كلمه للتاريخ فارس عوض لماذا الالغاا الهلال التعاون التعاون الهلال\n",
            "تعليق الدراسه في القصيم اتخذ القرار قبل منتصف الليل الامطار تسقط غزاره علي القصيم اي حدث يحدث لا سمح\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5FjwfNVjcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length = []\n",
        "for x in x_train:\n",
        "  length.append(len(x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfnor6gRVyt8",
        "colab_type": "code",
        "outputId": "329b692e-3b3b-4580-b22d-3305dcc6cad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max(length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmrbgQobVz_Y",
        "colab_type": "code",
        "outputId": "300777dd-67aa-4957-ed5e-d1f5187ab154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train_seq = pad_sequences(sequences, maxlen=35)\n",
        "print('Shape of data tensor: ', x_train_seq.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor:  (45338, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1u0kjKV9OR",
        "colab_type": "code",
        "outputId": "ff8e9611-868f-429e-d66e-aa8e6599d460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "x_train_seq[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,    69,    16,    92,   100,    84, 13248,\n",
              "          373,   212,  6944, 32195,    58,   224, 32196, 16290,   295,\n",
              "        21407, 32197,   345,   211,  8619,   295,  1845,     6],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,    69,    16,    92,   100, 16291,    21,   161, 32198,\n",
              "         1798, 21408,    51, 32199,    21, 32200, 11246, 32201],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,    29,    30,   500,\n",
              "          238,  7697,   583,     1,     2,   277,   805,  3513,  8620,\n",
              "        21409, 16292,    42,  8621,  2081,   296,   493,  1799],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,   106,  2661,\n",
              "          561,   874,    69,  5396,     1,    15,    15,     1],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     7,     8,\n",
              "            2,    12, 11247,   785,   103,  8622,  1185,   410,  6945,\n",
              "        13249,     4,    12,   102,  1975,  1643,    18,  5788]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucqpAKnpWAHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_val = tokenizer.texts_to_sequences(x_validation)\n",
        "x_val_seq = pad_sequences(sequences_val, maxlen=35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gHotEe_WLkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 100000\n",
        "embedding_matrix = np.zeros((num_words, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i >= num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55v0rpHYK-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 3\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3n12_TEklMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
        "x_test_seq = pad_sequences(sequences_test, maxlen=35)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWMHLs8wS44A",
        "colab_type": "code",
        "outputId": "81ab3d7a-4493-4c23-c659-70d39b10d169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!pip install keras_metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.18.1)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RgLtmcslz62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras_metrics\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHnM6jRmM2K1",
        "colab_type": "text"
      },
      "source": [
        "#**TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3xXCsmV5W93",
        "colab_type": "code",
        "outputId": "323c537f-0725-49fe-dcca-36e4a17feb15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "model_gru = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_gru.add(e)\n",
        "model_gru.add(keras.layers.GRU(256, dropout=0.4, recurrent_dropout=0.4))\n",
        "model_gru.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                  metrics=['accuracy', keras_metrics.precision(), \n",
        "                           keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_gru.summary()\n",
        "model_gru.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (None, 256)               350976    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 20,351,747\n",
            "Trainable params: 20,351,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 114s 3ms/step - loss: 0.6828 - acc: 0.7094 - precision: 0.7324 - recall: 0.6785 - f1_score: 0.7044 - val_loss: 0.5557 - val_acc: 0.7784 - val_precision: 0.7603 - val_recall: 0.8160 - val_f1_score: 0.7872\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 113s 3ms/step - loss: 0.5412 - acc: 0.7776 - precision: 0.7978 - recall: 0.7651 - f1_score: 0.7811 - val_loss: 0.5336 - val_acc: 0.7847 - val_precision: 0.8160 - val_recall: 0.7485 - val_f1_score: 0.7808\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 112s 2ms/step - loss: 0.4776 - acc: 0.8086 - precision: 0.8267 - recall: 0.8035 - f1_score: 0.8149 - val_loss: 0.5167 - val_acc: 0.7965 - val_precision: 0.8396 - val_recall: 0.7476 - val_f1_score: 0.7909\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 114s 3ms/step - loss: 0.4171 - acc: 0.8372 - precision: 0.8571 - recall: 0.8351 - f1_score: 0.8460 - val_loss: 0.5315 - val_acc: 0.7976 - val_precision: 0.8267 - val_recall: 0.7657 - val_f1_score: 0.7950\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 114s 3ms/step - loss: 0.3689 - acc: 0.8576 - precision: 0.8798 - recall: 0.8599 - f1_score: 0.8697 - val_loss: 0.5544 - val_acc: 0.7985 - val_precision: 0.8159 - val_recall: 0.7891 - val_f1_score: 0.8023\n",
            "CPU times: user 11min 26s, sys: 1min 34s, total: 13min\n",
            "Wall time: 9min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVlguXcL7h7p",
        "colab_type": "code",
        "outputId": "0c92d594-e89d-4a42-9a55-768759d7f2c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_gru.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 4s 726us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5300613816304365,\n",
              " 0.8057515878616796,\n",
              " 0.8281327389386759,\n",
              " 0.7969494756531483,\n",
              " 0.8122418737098276]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn7lMAsCNOI-",
        "colab_type": "code",
        "outputId": "47f2c00b-f395-46cc-87f7-de620a61c4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_st_gru = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_st_gru.add(e)\n",
        "# model_st_gru.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model_st_gru.add(keras.layers.GRU(64, dropout=0.2, recurrent_dropout=0.5, return_sequences=True))\n",
        "model_st_gru.add(keras.layers.GRU(128, dropout=0.2, return_sequences=True))\n",
        "model_st_gru.add(keras.layers.GRU(256, dropout=0.2))\n",
        "model_st_gru.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_st_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_st_gru.summary()\n",
        "model_st_gru.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 35, 64)            50880     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 35, 128)           74112     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 256)               295680    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 20,421,443\n",
            "Trainable params: 20,421,443\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 270s 6ms/step - loss: 0.6466 - acc: 0.7288 - precision: 0.7502 - recall: 0.7029 - f1_score: 0.7258 - val_loss: 0.5707 - val_acc: 0.7704 - val_precision: 0.8783 - val_recall: 0.6287 - val_f1_score: 0.7328\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 287s 6ms/step - loss: 0.5084 - acc: 0.7949 - precision: 0.8163 - recall: 0.7894 - f1_score: 0.8026 - val_loss: 0.5255 - val_acc: 0.7953 - val_precision: 0.8559 - val_recall: 0.7265 - val_f1_score: 0.7859\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 282s 6ms/step - loss: 0.4191 - acc: 0.8356 - precision: 0.8604 - recall: 0.8369 - f1_score: 0.8485 - val_loss: 0.5359 - val_acc: 0.7937 - val_precision: 0.8596 - val_recall: 0.7221 - val_f1_score: 0.7849\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 271s 6ms/step - loss: 0.3433 - acc: 0.8684 - precision: 0.8942 - recall: 0.8699 - f1_score: 0.8819 - val_loss: 0.5333 - val_acc: 0.7902 - val_precision: 0.8465 - val_recall: 0.7285 - val_f1_score: 0.7831\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 272s 6ms/step - loss: 0.2882 - acc: 0.8922 - precision: 0.9153 - recall: 0.8941 - f1_score: 0.9046 - val_loss: 0.5777 - val_acc: 0.7845 - val_precision: 0.8447 - val_recall: 0.7187 - val_f1_score: 0.7766\n",
            "CPU times: user 30min 49s, sys: 2min 33s, total: 33min 23s\n",
            "Wall time: 23min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU4SGfC_STa7",
        "colab_type": "code",
        "outputId": "d83758dd-671f-413e-f93d-6446a4e395c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_gru.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 4s 770us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5512950190079405,\n",
              " 0.8061044460127029,\n",
              " 0.8140655105580894,\n",
              " 0.8055290752714238,\n",
              " 0.8097747463210004]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khd2S__ge-Qh",
        "colab_type": "text"
      },
      "source": [
        "#**GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9vYAywmk1sV",
        "colab_type": "code",
        "outputId": "361c4f24-2abd-48cf-e816-f022850eeb69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "model_gru = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_gru.add(e)\n",
        "model_gru.add(keras.layers.GRU(256, dropout=0.2, recurrent_dropout=0.5))\n",
        "model_gru.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                  metrics=['accuracy', keras_metrics.precision(), \n",
        "                           keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_gru.summary()\n",
        "model_gru.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 256)               350976    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 20,351,747\n",
            "Trainable params: 20,351,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 104s 2ms/step - loss: 0.6369 - acc: 0.7327 - precision: 0.7561 - recall: 0.7091 - f1_score: 0.7318 - val_loss: 0.5531 - val_acc: 0.7688 - val_precision: 0.8338 - val_recall: 0.7094 - val_f1_score: 0.7666\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 101s 2ms/step - loss: 0.4837 - acc: 0.8067 - precision: 0.8218 - recall: 0.7928 - f1_score: 0.8071 - val_loss: 0.5089 - val_acc: 0.7980 - val_precision: 0.8134 - val_recall: 0.7891 - val_f1_score: 0.8011\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 100s 2ms/step - loss: 0.4068 - acc: 0.8388 - precision: 0.8573 - recall: 0.8358 - f1_score: 0.8464 - val_loss: 0.5106 - val_acc: 0.8017 - val_precision: 0.8347 - val_recall: 0.7632 - val_f1_score: 0.7973\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 99s 2ms/step - loss: 0.3378 - acc: 0.8694 - precision: 0.8904 - recall: 0.8722 - f1_score: 0.8812 - val_loss: 0.5358 - val_acc: 0.7994 - val_precision: 0.8405 - val_recall: 0.7476 - val_f1_score: 0.7913\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 99s 2ms/step - loss: 0.2785 - acc: 0.8941 - precision: 0.9139 - recall: 0.8988 - f1_score: 0.9063 - val_loss: 0.5738 - val_acc: 0.7980 - val_precision: 0.8244 - val_recall: 0.7740 - val_f1_score: 0.7984\n",
            "CPU times: user 10min 20s, sys: 1min 13s, total: 11min 33s\n",
            "Wall time: 8min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gbcibIMwqb4",
        "colab_type": "code",
        "outputId": "972c6b97-d5c2-49c9-ce89-28a36d1952a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_gru.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 4s 704us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5628368094637096,\n",
              " 0.8034580098800282,\n",
              " 0.8396907216062015,\n",
              " 0.7764537654539346,\n",
              " 0.8068350169013767]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2amLDvZfY-Z",
        "colab_type": "text"
      },
      "source": [
        "#**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WA0oqNNnJZN",
        "colab_type": "code",
        "outputId": "b4f451cf-7086-4ea4-988f-7d993cd31f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_lstm = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_lstm.add(e)\n",
        "# model_lstm.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model_lstm.add(keras.layers.LSTM(256, dropout=0.2, recurrent_dropout=0.5))\n",
        "model_lstm.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_lstm.summary()\n",
        "model_lstm.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               467968    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 20,468,739\n",
            "Trainable params: 20,468,739\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 115s 3ms/step - loss: 0.6064 - acc: 0.7477 - precision: 0.7693 - recall: 0.7210 - f1_score: 0.7444 - val_loss: 0.5205 - val_acc: 0.7914 - val_precision: 0.7940 - val_recall: 0.7921 - val_f1_score: 0.7930\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 114s 3ms/step - loss: 0.4675 - acc: 0.8122 - precision: 0.8340 - recall: 0.8011 - f1_score: 0.8172 - val_loss: 0.5046 - val_acc: 0.7964 - val_precision: 0.7990 - val_recall: 0.8092 - val_f1_score: 0.8041\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 114s 3ms/step - loss: 0.3819 - acc: 0.8507 - precision: 0.8727 - recall: 0.8469 - f1_score: 0.8596 - val_loss: 0.5050 - val_acc: 0.8059 - val_precision: 0.8180 - val_recall: 0.7852 - val_f1_score: 0.8013\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 116s 3ms/step - loss: 0.3030 - acc: 0.8843 - precision: 0.9057 - recall: 0.8870 - f1_score: 0.8963 - val_loss: 0.5365 - val_acc: 0.8050 - val_precision: 0.8347 - val_recall: 0.7632 - val_f1_score: 0.7973\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 118s 3ms/step - loss: 0.2423 - acc: 0.9088 - precision: 0.9258 - recall: 0.9110 - f1_score: 0.9184 - val_loss: 0.5680 - val_acc: 0.8032 - val_precision: 0.8289 - val_recall: 0.7725 - val_f1_score: 0.7997\n",
            "CPU times: user 12min 2s, sys: 1min 17s, total: 13min 20s\n",
            "Wall time: 9min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OszcZVoeioKB",
        "colab_type": "code",
        "outputId": "2fd73aa3-c14c-4213-de40-14c24fecb5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_lstm.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 5s 885us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5733786303137253,\n",
              " 0.8016937191249118,\n",
              " 0.8412039439106795,\n",
              " 0.7726406100680343,\n",
              " 0.8054657885595433]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZx-VtQqpwRs",
        "colab_type": "text"
      },
      "source": [
        "#**Bi-GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAs0dfY7pM5u",
        "colab_type": "code",
        "outputId": "6e3426eb-0465-461e-e43d-47dc8ea36d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_bi_gru = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_bi_gru.add(e)\n",
        "# model_gru.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model_bi_gru.add(keras.layers.Bidirectional(keras.layers.GRU(256, dropout=0.2, recurrent_dropout=0.5)))\n",
        "model_bi_gru.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_bi_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_bi_gru.summary()\n",
        "model_bi_gru.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               701952    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 20,703,491\n",
            "Trainable params: 20,703,491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 198s 4ms/step - loss: 0.6284 - acc: 0.7370 - precision: 0.7621 - recall: 0.7117 - f1_score: 0.7361 - val_loss: 0.5320 - val_acc: 0.7860 - val_precision: 0.8527 - val_recall: 0.6967 - val_f1_score: 0.7668\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 195s 4ms/step - loss: 0.4838 - acc: 0.8058 - precision: 0.8244 - recall: 0.7941 - f1_score: 0.8090 - val_loss: 0.5078 - val_acc: 0.7958 - val_precision: 0.8329 - val_recall: 0.7705 - val_f1_score: 0.8005\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 188s 4ms/step - loss: 0.4065 - acc: 0.8383 - precision: 0.8603 - recall: 0.8327 - f1_score: 0.8462 - val_loss: 0.5216 - val_acc: 0.7978 - val_precision: 0.8582 - val_recall: 0.7285 - val_f1_score: 0.7880\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 187s 4ms/step - loss: 0.3402 - acc: 0.8696 - precision: 0.8900 - recall: 0.8702 - f1_score: 0.8800 - val_loss: 0.5318 - val_acc: 0.7985 - val_precision: 0.8177 - val_recall: 0.7833 - val_f1_score: 0.8001\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 186s 4ms/step - loss: 0.2816 - acc: 0.8926 - precision: 0.9086 - recall: 0.8962 - f1_score: 0.9024 - val_loss: 0.5709 - val_acc: 0.7962 - val_precision: 0.8350 - val_recall: 0.7554 - val_f1_score: 0.7932\n",
            "CPU times: user 22min 16s, sys: 3min 7s, total: 25min 23s\n",
            "Wall time: 15min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDNWGeJ0l86B",
        "colab_type": "code",
        "outputId": "3853bdfa-f877-40fc-fa0d-64ac9ff0a6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_bi_gru.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 8s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5635861348920753,\n",
              " 0.7972829922371206,\n",
              " 0.8499730166837575,\n",
              " 0.750714966599108,\n",
              " 0.7972664649582831]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37I5JNiZqmq-",
        "colab_type": "text"
      },
      "source": [
        "#**Bi-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JlK_s2useCi",
        "colab_type": "code",
        "outputId": "830937d1-adf6-44aa-940c-051f714c9c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_bi_lstm = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_bi_lstm.add(e)\n",
        "# model_lstm.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model_bi_lstm.add(keras.layers.Bidirectional(keras.layers.LSTM(256, dropout=0.2, recurrent_dropout=0.5)))\n",
        "model_bi_lstm.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_bi_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_bi_lstm.summary()\n",
        "model_bi_lstm.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 512)               935936    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 20,937,475\n",
            "Trainable params: 20,937,475\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 229s 5ms/step - loss: 0.6030 - acc: 0.7489 - precision: 0.7735 - recall: 0.7214 - f1_score: 0.7465 - val_loss: 0.5474 - val_acc: 0.7762 - val_precision: 0.8639 - val_recall: 0.6678 - val_f1_score: 0.7533\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 236s 5ms/step - loss: 0.4697 - acc: 0.8095 - precision: 0.8304 - recall: 0.8024 - f1_score: 0.8162 - val_loss: 0.5087 - val_acc: 0.8024 - val_precision: 0.8233 - val_recall: 0.7794 - val_f1_score: 0.8007\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 239s 5ms/step - loss: 0.3781 - acc: 0.8505 - precision: 0.8717 - recall: 0.8468 - f1_score: 0.8590 - val_loss: 0.5234 - val_acc: 0.8029 - val_precision: 0.8731 - val_recall: 0.7104 - val_f1_score: 0.7834\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 231s 5ms/step - loss: 0.2993 - acc: 0.8854 - precision: 0.9050 - recall: 0.8859 - f1_score: 0.8953 - val_loss: 0.5404 - val_acc: 0.8011 - val_precision: 0.8401 - val_recall: 0.7505 - val_f1_score: 0.7928\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 224s 5ms/step - loss: 0.2409 - acc: 0.9090 - precision: 0.9273 - recall: 0.9129 - f1_score: 0.9201 - val_loss: 0.5750 - val_acc: 0.7992 - val_precision: 0.8485 - val_recall: 0.7343 - val_f1_score: 0.7873\n",
            "CPU times: user 27min 11s, sys: 3min 51s, total: 31min 2s\n",
            "Wall time: 19min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp7bd-UB1VQn",
        "colab_type": "code",
        "outputId": "8a3eba4a-836b-4565-8f79-c873a3db7b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_bi_lstm.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 9s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5793126914268997,\n",
              " 0.7997529992942837,\n",
              " 0.8698358799734105,\n",
              " 0.732602478516082,\n",
              " 0.7953427705066731]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8ImVzHRrUAN",
        "colab_type": "text"
      },
      "source": [
        "#**Stacked GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzu1Snk71ea_",
        "colab_type": "code",
        "outputId": "0d6fd892-b331-411f-87e1-c4664ef0203e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_st_gru = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_st_gru.add(e)\n",
        "# model_st_gru.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model_st_gru.add(keras.layers.GRU(64, dropout=0.2, recurrent_dropout=0.5, return_sequences=True))\n",
        "model_st_gru.add(keras.layers.GRU(128, dropout=0.2))\n",
        "model_st_gru.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_st_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_st_gru.summary()\n",
        "model_st_gru.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 35, 64)            50880     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 128)               74112     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 20,125,379\n",
            "Trainable params: 20,125,379\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 165s 4ms/step - loss: 0.6390 - acc: 0.7319 - precision: 0.7586 - recall: 0.7088 - f1_score: 0.7329 - val_loss: 0.5426 - val_acc: 0.7800 - val_precision: 0.8427 - val_recall: 0.7050 - val_f1_score: 0.7677\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 164s 4ms/step - loss: 0.4935 - acc: 0.8025 - precision: 0.8220 - recall: 0.7953 - f1_score: 0.8084 - val_loss: 0.5177 - val_acc: 0.7946 - val_precision: 0.8371 - val_recall: 0.7441 - val_f1_score: 0.7879\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 164s 4ms/step - loss: 0.4086 - acc: 0.8401 - precision: 0.8628 - recall: 0.8401 - f1_score: 0.8513 - val_loss: 0.5131 - val_acc: 0.7964 - val_precision: 0.8422 - val_recall: 0.7387 - val_f1_score: 0.7871\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 165s 4ms/step - loss: 0.3282 - acc: 0.8750 - precision: 0.8982 - recall: 0.8795 - f1_score: 0.8887 - val_loss: 0.5397 - val_acc: 0.7921 - val_precision: 0.8220 - val_recall: 0.7500 - val_f1_score: 0.7843\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 161s 4ms/step - loss: 0.2712 - acc: 0.8963 - precision: 0.9202 - recall: 0.8991 - f1_score: 0.9095 - val_loss: 0.5622 - val_acc: 0.7948 - val_precision: 0.8261 - val_recall: 0.7598 - val_f1_score: 0.7915\n",
            "CPU times: user 17min 59s, sys: 1min 33s, total: 19min 33s\n",
            "Wall time: 13min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKmviBBe2TtP",
        "colab_type": "code",
        "outputId": "e69c94cc-936f-483a-e9f7-041bd3b9c87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_st_gru.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 7s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5480669759156086,\n",
              " 0.805045871559633,\n",
              " 0.8445487740821831,\n",
              " 0.7716873212215593,\n",
              " 0.8064756661262017]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9jdWbVfrfal",
        "colab_type": "text"
      },
      "source": [
        "#**Stacked LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnqmDngK5r6y",
        "colab_type": "code",
        "outputId": "fe0c4110-2547-4838-8752-6a131009ea39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_st_lstm = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_st_lstm.add(e)\n",
        "# model_st_gru.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model_st_lstm.add(keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.5, return_sequences=True))\n",
        "model_st_lstm.add(keras.layers.LSTM(128, dropout=0.2))\n",
        "model_st_lstm.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_st_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall(), keras_metrics.f1_score()])\n",
        "model_st_lstm.summary()\n",
        "model_st_lstm.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 35, 64)            67840     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 20,167,043\n",
            "Trainable params: 20,167,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 195s 4ms/step - loss: 0.6336 - acc: 0.7366 - precision: 0.7635 - recall: 0.7068 - f1_score: 0.7341 - val_loss: 0.5384 - val_acc: 0.7844 - val_precision: 0.8373 - val_recall: 0.7177 - val_f1_score: 0.7729\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 190s 4ms/step - loss: 0.4882 - acc: 0.8040 - precision: 0.8232 - recall: 0.7977 - f1_score: 0.8103 - val_loss: 0.5061 - val_acc: 0.7972 - val_precision: 0.8682 - val_recall: 0.6991 - val_f1_score: 0.7745\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 189s 4ms/step - loss: 0.4021 - acc: 0.8422 - precision: 0.8644 - recall: 0.8395 - f1_score: 0.8518 - val_loss: 0.4999 - val_acc: 0.8100 - val_precision: 0.8266 - val_recall: 0.7813 - val_f1_score: 0.8033\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 191s 4ms/step - loss: 0.3308 - acc: 0.8720 - precision: 0.8946 - recall: 0.8752 - f1_score: 0.8848 - val_loss: 0.5173 - val_acc: 0.8050 - val_precision: 0.8285 - val_recall: 0.7632 - val_f1_score: 0.7945\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 196s 4ms/step - loss: 0.2700 - acc: 0.8979 - precision: 0.9231 - recall: 0.9034 - f1_score: 0.9132 - val_loss: 0.5540 - val_acc: 0.7953 - val_precision: 0.8303 - val_recall: 0.7637 - val_f1_score: 0.7956\n",
            "CPU times: user 21min 8s, sys: 1min 47s, total: 22min 56s\n",
            "Wall time: 16min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqyX-3zC5-MW",
        "colab_type": "code",
        "outputId": "ec1aa6b4-d4b8-4e94-e2df-da554fb3fcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_st_lstm.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 8s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5411306851837276,\n",
              " 0.8041637261820748,\n",
              " 0.844027125673238,\n",
              " 0.7712106767983218,\n",
              " 0.8059775341212453]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ko9YNgfsn2B",
        "colab_type": "text"
      },
      "source": [
        "#**Stacked Bi-GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4eaKqU50An8",
        "colab_type": "code",
        "outputId": "57a443c3-3254-43a4-bce9-9f14fbe55f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "%%time\n",
        "model_StBiGRU_input = layers.Input(shape=(x_train_seq.shape[1],))\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)(model_StBiGRU_input)\n",
        "\n",
        "forw = layers.GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "backw = layers.GRU(64, return_sequences=True, go_backwards=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "\n",
        "\n",
        "forw2 = layers.GRU(128, dropout=0.2)(forw)\n",
        "backw2 = layers.GRU(128, go_backwards=True, dropout=0.2)(backw)\n",
        "link= layers.Concatenate()([forw2,backw2])\n",
        "\n",
        "x = layers.Dense(3, activation='softmax')(link)\n",
        "\n",
        "model_StBiGRU = keras.models.Model(inputs=model_StBiGRU_input, outputs=x)\n",
        "\n",
        "model_StBiGRU.compile(loss='categorical_crossentropy', \n",
        "                        optimizer='adam', \n",
        "                        metrics=['accuracy', \n",
        "                                 keras_metrics.precision(), \n",
        "                                 keras_metrics.recall(), \n",
        "                                 keras_metrics.f1_score()])\n",
        "model_StBiGRU.summary()\n",
        "model_StBiGRU.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 35, 200)      20000000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_5 (GRU)                     (None, 35, 64)       50880       embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gru_6 (GRU)                     (None, 35, 64)       50880       embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gru_7 (GRU)                     (None, 128)          74112       gru_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru_8 (GRU)                     (None, 128)          74112       gru_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           gru_7[0][0]                      \n",
            "                                                                 gru_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 3)            771         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 20,250,755\n",
            "Trainable params: 20,250,755\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 361s 8ms/step - loss: 0.6304 - acc: 0.7357 - precision: 0.7587 - recall: 0.7093 - f1_score: 0.7332 - val_loss: 0.5418 - val_acc: 0.7824 - val_precision: 0.8418 - val_recall: 0.7055 - val_f1_score: 0.7676\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 349s 8ms/step - loss: 0.4776 - acc: 0.8083 - precision: 0.8263 - recall: 0.8050 - f1_score: 0.8155 - val_loss: 0.5016 - val_acc: 0.7988 - val_precision: 0.8262 - val_recall: 0.7886 - val_f1_score: 0.8070\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 342s 8ms/step - loss: 0.3829 - acc: 0.8509 - precision: 0.8702 - recall: 0.8536 - f1_score: 0.8618 - val_loss: 0.5221 - val_acc: 0.8015 - val_precision: 0.8348 - val_recall: 0.7764 - val_f1_score: 0.8046\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 338s 7ms/step - loss: 0.3018 - acc: 0.8852 - precision: 0.9089 - recall: 0.8892 - f1_score: 0.8989 - val_loss: 0.5615 - val_acc: 0.7976 - val_precision: 0.8388 - val_recall: 0.7534 - val_f1_score: 0.7938\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 331s 7ms/step - loss: 0.2433 - acc: 0.9076 - precision: 0.9291 - recall: 0.9130 - f1_score: 0.9210 - val_loss: 0.5887 - val_acc: 0.7957 - val_precision: 0.8212 - val_recall: 0.7661 - val_f1_score: 0.7927\n",
            "CPU times: user 41min 48s, sys: 5min 48s, total: 47min 37s\n",
            "Wall time: 28min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hz7zex8HFIy",
        "colab_type": "code",
        "outputId": "6f887ba7-4d88-45fd-bf1e-e07d0ee48ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_StBiGRU.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 14s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5879813143293371,\n",
              " 0.7985179957657021,\n",
              " 0.8304123710912158,\n",
              " 0.767874165835659,\n",
              " 0.7979197122955777]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk3SNG4GHk2_",
        "colab_type": "text"
      },
      "source": [
        "#**Stacked Bi-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHzH-SzrIE2y",
        "colab_type": "code",
        "outputId": "1d02b977-e425-4820-dede-91cbcbeb97c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "%%time\n",
        "model_StBiLSTM_input = layers.Input(shape=(x_train_seq.shape[1],))\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)(model_StBiLSTM_input)\n",
        "\n",
        "forw = layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "backw = layers.LSTM(64, return_sequences=True, go_backwards=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "\n",
        "\n",
        "forw2 = layers.LSTM(128, dropout=0.2)(forw)\n",
        "backw2 = layers.LSTM(128, go_backwards=True, dropout=0.2)(backw)\n",
        "link= layers.Concatenate()([forw2,backw2])\n",
        "\n",
        "x = layers.Dense(3, activation='softmax')(link)\n",
        "\n",
        "model_StBiLSTM = keras.models.Model(inputs=model_StBiLSTM_input, outputs=x)\n",
        "\n",
        "model_StBiLSTM.compile(loss='categorical_crossentropy', \n",
        "                        optimizer='adam', \n",
        "                        metrics=['accuracy', \n",
        "                                 keras_metrics.precision(), \n",
        "                                 keras_metrics.recall(), \n",
        "                                 keras_metrics.f1_score()])\n",
        "model_StBiLSTM.summary()\n",
        "model_StBiLSTM.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 35, 200)      20000000    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 35, 64)       67840       embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 35, 64)       67840       embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 128)          98816       lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 128)          98816       lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           lstm_7[0][0]                     \n",
            "                                                                 lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 3)            771         concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 20,334,083\n",
            "Trainable params: 20,334,083\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 410s 9ms/step - loss: 0.6173 - acc: 0.7436 - precision: 0.7729 - recall: 0.7102 - f1_score: 0.7402 - val_loss: 0.5404 - val_acc: 0.7842 - val_precision: 0.7850 - val_recall: 0.7931 - val_f1_score: 0.7890\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 408s 9ms/step - loss: 0.4773 - acc: 0.8100 - precision: 0.8298 - recall: 0.7993 - f1_score: 0.8143 - val_loss: 0.5135 - val_acc: 0.7946 - val_precision: 0.8466 - val_recall: 0.7211 - val_f1_score: 0.7789\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 405s 9ms/step - loss: 0.3895 - acc: 0.8478 - precision: 0.8699 - recall: 0.8439 - f1_score: 0.8567 - val_loss: 0.5107 - val_acc: 0.8025 - val_precision: 0.8363 - val_recall: 0.7622 - val_f1_score: 0.7975\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 405s 9ms/step - loss: 0.3119 - acc: 0.8803 - precision: 0.9016 - recall: 0.8852 - f1_score: 0.8933 - val_loss: 0.5442 - val_acc: 0.8048 - val_precision: 0.8563 - val_recall: 0.7378 - val_f1_score: 0.7926\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 406s 9ms/step - loss: 0.2486 - acc: 0.9069 - precision: 0.9269 - recall: 0.9118 - f1_score: 0.9193 - val_loss: 0.5860 - val_acc: 0.8024 - val_precision: 0.8472 - val_recall: 0.7378 - val_f1_score: 0.7887\n",
            "CPU times: user 49min 15s, sys: 7min 26s, total: 56min 41s\n",
            "Wall time: 34min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kut6xFOnIX-8",
        "colab_type": "code",
        "outputId": "e793f13a-52fd-4b24-e9e0-6dff7ef6c1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_StBiLSTM.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 18s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5795366378342003,\n",
              " 0.8022230063514467,\n",
              " 0.8661814109257456,\n",
              " 0.7373689227484572,\n",
              " 0.7966013920941897]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJdAbjzbIfh1",
        "colab_type": "text"
      },
      "source": [
        "#**Concatenated BI-GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4OtYFjD5HKK",
        "colab_type": "code",
        "outputId": "839c3d65-33f9-4ecf-96e5-57ec4269d2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_st_bi_gru = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_st_bi_gru.add(e)\n",
        "model_st_bi_gru.add(keras.layers.Bidirectional(\n",
        "    keras.layers.GRU(64, dropout=0.2, recurrent_dropout=0.5, \n",
        "                      return_sequences=True)))\n",
        "model_st_bi_gru.add(keras.layers.Bidirectional(\n",
        "    keras.layers.GRU(128, dropout=0.2)))\n",
        "model_st_bi_gru.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_st_bi_gru.compile(loss='categorical_crossentropy', \n",
        "                        optimizer='adam', \n",
        "                        metrics=['accuracy', \n",
        "                                 keras_metrics.precision(), \n",
        "                                 keras_metrics.recall(), \n",
        "                                 keras_metrics.f1_score()])\n",
        "model_st_bi_gru.summary()\n",
        "model_st_bi_gru.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 35, 128)           101760    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 256)               197376    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 20,299,907\n",
            "Trainable params: 20,299,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 317s 7ms/step - loss: 0.6178 - acc: 0.7413 - precision: 0.7703 - recall: 0.7147 - f1_score: 0.7415 - val_loss: 0.5353 - val_acc: 0.7849 - val_precision: 0.8583 - val_recall: 0.6967 - val_f1_score: 0.7691\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 312s 7ms/step - loss: 0.4656 - acc: 0.8153 - precision: 0.8343 - recall: 0.8106 - f1_score: 0.8223 - val_loss: 0.5061 - val_acc: 0.7974 - val_precision: 0.8353 - val_recall: 0.7568 - val_f1_score: 0.7941\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 310s 7ms/step - loss: 0.3686 - acc: 0.8576 - precision: 0.8792 - recall: 0.8575 - f1_score: 0.8682 - val_loss: 0.5214 - val_acc: 0.7987 - val_precision: 0.8340 - val_recall: 0.7568 - val_f1_score: 0.7935\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 312s 7ms/step - loss: 0.2873 - acc: 0.8918 - precision: 0.9142 - recall: 0.8957 - f1_score: 0.9049 - val_loss: 0.5824 - val_acc: 0.7916 - val_precision: 0.8623 - val_recall: 0.7016 - val_f1_score: 0.7737\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 314s 7ms/step - loss: 0.2313 - acc: 0.9125 - precision: 0.9329 - recall: 0.9157 - f1_score: 0.9242 - val_loss: 0.6089 - val_acc: 0.7902 - val_precision: 0.8427 - val_recall: 0.7260 - val_f1_score: 0.7800\n",
            "CPU times: user 36min 55s, sys: 4min 7s, total: 41min 3s\n",
            "Wall time: 26min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZrh4GW8JI3n",
        "colab_type": "code",
        "outputId": "c20e7394-bc0e-4529-8430-6f8ad39120a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_st_bi_gru.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 14s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5910256639196575,\n",
              " 0.7979887085391673,\n",
              " 0.8586533110262297,\n",
              " 0.7354623450555071,\n",
              " 0.7922977679729384]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfGUV0HtJNST",
        "colab_type": "text"
      },
      "source": [
        "#**Concatenated Bi-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saPaeaEK-Ihc",
        "colab_type": "code",
        "outputId": "9d66cca6-864e-48e2-b007-f07904ad08e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model_st_bi_lstm = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)\n",
        "model_st_bi_lstm.add(e)\n",
        "model_st_bi_lstm.add(keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.5, \n",
        "                      return_sequences=True)))\n",
        "model_st_bi_lstm.add(keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(128, dropout=0.2)))\n",
        "model_st_bi_lstm.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model_st_bi_lstm.compile(loss='categorical_crossentropy', \n",
        "                        optimizer='adam', \n",
        "                        metrics=['accuracy', \n",
        "                                 keras_metrics.precision(), \n",
        "                                 keras_metrics.recall(), \n",
        "                                 keras_metrics.f1_score()])\n",
        "model_st_bi_lstm.summary()\n",
        "model_st_bi_lstm.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 35, 200)           20000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 35, 128)           135680    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 20,399,619\n",
            "Trainable params: 20,399,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 381s 8ms/step - loss: 0.6100 - acc: 0.7488 - precision: 0.7754 - recall: 0.7237 - f1_score: 0.7487 - val_loss: 0.5263 - val_acc: 0.7868 - val_precision: 0.7975 - val_recall: 0.7764 - val_f1_score: 0.7868\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 379s 8ms/step - loss: 0.4707 - acc: 0.8138 - precision: 0.8336 - recall: 0.8081 - f1_score: 0.8207 - val_loss: 0.5104 - val_acc: 0.7946 - val_precision: 0.8483 - val_recall: 0.7441 - val_f1_score: 0.7928\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 381s 8ms/step - loss: 0.3754 - acc: 0.8534 - precision: 0.8777 - recall: 0.8522 - f1_score: 0.8648 - val_loss: 0.5086 - val_acc: 0.8047 - val_precision: 0.8433 - val_recall: 0.7583 - val_f1_score: 0.7986\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 380s 8ms/step - loss: 0.2980 - acc: 0.8865 - precision: 0.9080 - recall: 0.8902 - f1_score: 0.8990 - val_loss: 0.5390 - val_acc: 0.7988 - val_precision: 0.8194 - val_recall: 0.7857 - val_f1_score: 0.8022\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 378s 8ms/step - loss: 0.2363 - acc: 0.9124 - precision: 0.9331 - recall: 0.9152 - f1_score: 0.9241 - val_loss: 0.5726 - val_acc: 0.7995 - val_precision: 0.8212 - val_recall: 0.7754 - val_f1_score: 0.7977\n",
            "CPU times: user 44min 35s, sys: 5min 10s, total: 49min 46s\n",
            "Wall time: 32min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r4Akm5IRZhC",
        "colab_type": "code",
        "outputId": "399ed014-57e7-404c-bb28-e080c726a450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_st_bi_lstm.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 17s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5684865785469534,\n",
              " 0.8032815808045166,\n",
              " 0.8315467074613809,\n",
              " 0.7764537654539346,\n",
              " 0.8030563956686027]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLTj46aZBWji",
        "colab_type": "text"
      },
      "source": [
        "#**Concatenated Bi-GRU (2)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jveIF1d7szh",
        "colab_type": "code",
        "outputId": "9151b4a0-c33e-49d1-f8ee-17a5737e0a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "%%time\n",
        "model_ConGRU_input = layers.Input(shape=(x_train_seq.shape[1],))\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)(model_ConGRU_input)\n",
        "\n",
        "forw = layers.GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "backw = layers.GRU(64, return_sequences=True, go_backwards=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "\n",
        "link= layers.Concatenate()([forw,backw])\n",
        "\n",
        "forw2 = layers.GRU(64, dropout=0.2)(link)\n",
        "backw2 = layers.GRU(64, go_backwards=True, dropout=0.2)(link)\n",
        "link2= layers.Concatenate()([forw2,backw2])\n",
        "\n",
        "x = layers.Dense(3, activation='softmax')(link2)\n",
        "\n",
        "model_ConGRU = keras.models.Model(inputs=model_ConGRU_input, outputs=x)\n",
        "\n",
        "model_ConGRU.compile(loss='categorical_crossentropy', \n",
        "                        optimizer='adam', \n",
        "                        metrics=['accuracy', \n",
        "                                 keras_metrics.precision(), \n",
        "                                 keras_metrics.recall(), \n",
        "                                 keras_metrics.f1_score()])\n",
        "model_ConGRU.summary()\n",
        "model_ConGRU.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_15 (Embedding)        (None, 35, 200)      20000000    input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_19 (GRU)                    (None, 35, 64)       50880       embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "gru_20 (GRU)                    (None, 35, 64)       50880       embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 35, 128)      0           gru_19[0][0]                     \n",
            "                                                                 gru_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru_21 (GRU)                    (None, 64)           37056       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gru_22 (GRU)                    (None, 64)           37056       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 128)          0           gru_21[0][0]                     \n",
            "                                                                 gru_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 3)            387         concatenate_12[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 20,176,259\n",
            "Trainable params: 20,176,259\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 321s 7ms/step - loss: 0.6276 - acc: 0.7357 - precision: 0.7628 - recall: 0.7067 - f1_score: 0.7336 - val_loss: 0.5441 - val_acc: 0.7822 - val_precision: 0.8584 - val_recall: 0.6732 - val_f1_score: 0.7546\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 313s 7ms/step - loss: 0.4804 - acc: 0.8083 - precision: 0.8261 - recall: 0.7993 - f1_score: 0.8125 - val_loss: 0.5079 - val_acc: 0.8013 - val_precision: 0.8268 - val_recall: 0.7779 - val_f1_score: 0.8016\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 325s 7ms/step - loss: 0.3858 - acc: 0.8512 - precision: 0.8701 - recall: 0.8526 - f1_score: 0.8612 - val_loss: 0.5189 - val_acc: 0.8054 - val_precision: 0.8552 - val_recall: 0.7510 - val_f1_score: 0.7997\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 326s 7ms/step - loss: 0.3032 - acc: 0.8843 - precision: 0.9067 - recall: 0.8867 - f1_score: 0.8966 - val_loss: 0.5410 - val_acc: 0.8011 - val_precision: 0.8583 - val_recall: 0.7348 - val_f1_score: 0.7918\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 332s 7ms/step - loss: 0.2475 - acc: 0.9055 - precision: 0.9285 - recall: 0.9094 - f1_score: 0.9189 - val_loss: 0.5844 - val_acc: 0.7967 - val_precision: 0.8144 - val_recall: 0.7838 - val_f1_score: 0.7988\n",
            "CPU times: user 38min 56s, sys: 3min 50s, total: 42min 47s\n",
            "Wall time: 27min 42s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hueAd6W7ytx",
        "colab_type": "code",
        "outputId": "60f20800-0cc8-4caf-ff40-3c0ccb4c156b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_ConGRU.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 16s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.575116395066974,\n",
              " 0.7974594213126324,\n",
              " 0.8275686673027686,\n",
              " 0.7755004766074595,\n",
              " 0.8006889263913004]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnNK7HwFBRc2",
        "colab_type": "text"
      },
      "source": [
        "#**Concatenated Bi-LSTM (2)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N74J3q4L8rml",
        "colab_type": "code",
        "outputId": "c96deece-e231-4370-9bba-e419e3d82c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "%%time\n",
        "model_ConLSTM_input = layers.Input(shape=(x_train_seq.shape[1],))\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=35\n",
        "              , trainable=True)(model_ConLSTM_input)\n",
        "\n",
        "forw = layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "backw = layers.LSTM(64, return_sequences=True, go_backwards=True, dropout=0.2, recurrent_dropout=0.5)(e)\n",
        "\n",
        "link= layers.Concatenate()([forw,backw])\n",
        "\n",
        "forw2 = layers.LSTM(64, dropout=0.2)(link)\n",
        "backw2 = layers.LSTM(64, go_backwards=True, dropout=0.2)(link)\n",
        "link2= layers.Concatenate()([forw2,backw2])\n",
        "\n",
        "x = layers.Dense(3, activation='softmax')(link2)\n",
        "\n",
        "model_ConLSTM = keras.models.Model(inputs=model_ConLSTM_input, outputs=x)\n",
        "\n",
        "model_ConLSTM.compile(loss='categorical_crossentropy', \n",
        "                        optimizer='adam', \n",
        "                        metrics=['accuracy', \n",
        "                                 keras_metrics.precision(), \n",
        "                                 keras_metrics.recall(), \n",
        "                                 keras_metrics.f1_score()])\n",
        "model_ConLSTM.summary()\n",
        "model_ConLSTM.fit(x_train_seq, y_train, \n",
        "          validation_data=(x_val_seq, y_validation),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_16 (Embedding)        (None, 35, 200)      20000000    input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_19 (LSTM)                  (None, 35, 64)       67840       embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_20 (LSTM)                  (None, 35, 64)       67840       embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 35, 128)      0           lstm_19[0][0]                    \n",
            "                                                                 lstm_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_21 (LSTM)                  (None, 64)           49408       concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lstm_22 (LSTM)                  (None, 64)           49408       concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 128)          0           lstm_21[0][0]                    \n",
            "                                                                 lstm_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 3)            387         concatenate_14[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 20,234,883\n",
            "Trainable params: 20,234,883\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 45338 samples, validate on 5667 samples\n",
            "Epoch 1/5\n",
            "45338/45338 [==============================] - 410s 9ms/step - loss: 0.6105 - acc: 0.7462 - precision: 0.7760 - recall: 0.7141 - f1_score: 0.7438 - val_loss: 0.5305 - val_acc: 0.7881 - val_precision: 0.8073 - val_recall: 0.7524 - val_f1_score: 0.7789\n",
            "Epoch 2/5\n",
            "45338/45338 [==============================] - 407s 9ms/step - loss: 0.4739 - acc: 0.8126 - precision: 0.8351 - recall: 0.7998 - f1_score: 0.8171 - val_loss: 0.5026 - val_acc: 0.7951 - val_precision: 0.7879 - val_recall: 0.8180 - val_f1_score: 0.8027\n",
            "Epoch 3/5\n",
            "45338/45338 [==============================] - 408s 9ms/step - loss: 0.3844 - acc: 0.8501 - precision: 0.8721 - recall: 0.8499 - f1_score: 0.8608 - val_loss: 0.5136 - val_acc: 0.7978 - val_precision: 0.8300 - val_recall: 0.7691 - val_f1_score: 0.7984\n",
            "Epoch 4/5\n",
            "45338/45338 [==============================] - 403s 9ms/step - loss: 0.3094 - acc: 0.8819 - precision: 0.9046 - recall: 0.8864 - f1_score: 0.8954 - val_loss: 0.5283 - val_acc: 0.7988 - val_precision: 0.8101 - val_recall: 0.7975 - val_f1_score: 0.8037\n",
            "Epoch 5/5\n",
            "45338/45338 [==============================] - 399s 9ms/step - loss: 0.2513 - acc: 0.9061 - precision: 0.9276 - recall: 0.9095 - f1_score: 0.9185 - val_loss: 0.5686 - val_acc: 0.7990 - val_precision: 0.8433 - val_recall: 0.7373 - val_f1_score: 0.7867\n",
            "CPU times: user 48min 52s, sys: 4min 46s, total: 53min 38s\n",
            "Wall time: 34min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPjM_s9z8xis",
        "colab_type": "code",
        "outputId": "5c6c1f31-9199-4460-ee3f-17c3d429f4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "model_ConLSTM.evaluate(x_test_seq, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5668/5668 [==============================] - 19s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5654549431279249,\n",
              " 0.80257586450247,\n",
              " 0.8646239553835864,\n",
              " 0.7397521448646448,\n",
              " 0.7973284886641925]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}